"""å¤§æ¨¡å‹è°ƒç”¨å°è£…æ¨¡å— - ä¼˜åŒ–ç‰ˆ"""
import json
import time
from typing import Dict, Any, Optional
from openai import OpenAI, APIError, APIConnectionError, RateLimitError

from config.settings import AIConfig, settings
from core.prompt_builder import get_system_prompt, build_user_prompt


class AIClientError(Exception):
    """AI å®¢æˆ·ç«¯é”™è¯¯åŸºç±»"""
    pass


class APIKeyError(AIClientError):
    """API Key é”™è¯¯"""
    pass


class RateLimitExceeded(AIClientError):
    """API é™æµé”™è¯¯"""
    pass


class JSONParseError(AIClientError):
    """JSON è§£æé”™è¯¯"""
    pass


class NetworkError(AIClientError):
    """ç½‘ç»œé”™è¯¯"""
    pass


def _clean_json_response(content: str) -> str:
    """æ¸…ç† AI è¿”å›çš„ JSON å†…å®¹"""
    content = content.strip()
    
    # ç§»é™¤ markdown ä»£ç å—
    if content.startswith("```json"):
        content = content[7:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    content = content.strip()
    
    # æå– JSON éƒ¨åˆ†
    first_brace = content.find('{')
    last_brace = content.rfind('}')
    if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
        content = content[first_brace:last_brace + 1]
    
    # æ›¿æ¢ä¸­æ–‡å¼•å·
    content = content.replace('"', '"').replace('"', '"')
    content = content.replace(''', "'").replace(''', "'")
    
    # ç§»é™¤ BOM
    if content.startswith('\ufeff'):
        content = content[1:]
    
    return content


def _call_api_with_retry(
    client: OpenAI,
    model_name: str,
    system_prompt: str,
    user_prompt: str,
    max_retries: int = 3,
    temperature: float = 0.7
) -> str:
    """å¸¦é‡è¯•æœºåˆ¶çš„ API è°ƒç”¨"""
    is_claude = "claude" in model_name.lower()
    last_error = None
    
    for attempt in range(max_retries):
        try:
            if is_claude:
                # Claude æ¨¡å‹ï¼šåˆå¹¶ system å’Œ user prompt
                combined_prompt = f"{system_prompt}\n\n{user_prompt}"
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": combined_prompt}],
                    temperature=temperature,
                    max_tokens=8192
                )
            else:
                # OpenAI æ¨¡å‹ï¼šä½¿ç”¨æ ‡å‡†æ ¼å¼
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=temperature,
                    max_tokens=8192,
                    response_format={"type": "json_object"}
                )
            
            # æå–å“åº”å†…å®¹
            content = None
            if isinstance(response, str):
                content = response
            elif hasattr(response, 'choices') and response.choices:
                message = response.choices[0].message
                content = message.content if message else None
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content:
                raise AIClientError("AI è¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·é‡è¯•æˆ–æ›´æ¢æ¨¡å‹")
            
            return content
            
        except RateLimitError as e:
            last_error = e
            if attempt < max_retries - 1:
                wait_time = (2 ** attempt) * 2  # æŒ‡æ•°é€€é¿: 2, 4, 8 ç§’
                print(f"âš ï¸ API é™æµï¼Œ{wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise RateLimitExceeded(f"API é™æµï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                
        except APIConnectionError as e:
            last_error = e
            if attempt < max_retries - 1:
                wait_time = (2 ** attempt)
                print(f"âš ï¸ ç½‘ç»œé”™è¯¯ï¼Œ{wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise NetworkError(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                
        except APIError as e:
            if "invalid_api_key" in str(e).lower() or "401" in str(e):
                raise APIKeyError(f"API Key æ— æ•ˆ: {e}")
            last_error = e
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise AIClientError(f"API è°ƒç”¨å¤±è´¥: {e}")
    
    raise AIClientError(f"API è°ƒç”¨å¤±è´¥: {last_error}")


def _calculate_batches(page_count: int) -> list:
    """è®¡ç®—åˆ†æ‰¹ç­–ç•¥
    
    è§„åˆ™ï¼š
    - 35é¡µåŠä»¥ä¸‹ï¼š1æ‰¹
    - 36-70é¡µï¼š2æ‰¹
    - 71-100é¡µï¼š3æ‰¹
    - 101-150é¡µï¼š3æ‰¹ï¼ˆæ¯æ‰¹çº¦50é¡µï¼‰
    - 151-200é¡µï¼š4æ‰¹ï¼ˆæ¯æ‰¹çº¦50é¡µï¼‰
    """
    if page_count <= 35:
        return [page_count]
    elif page_count <= 70:
        # 2æ‰¹ï¼Œå°½é‡å‡åˆ†
        half = page_count // 2
        return [half, page_count - half]
    elif page_count <= 100:
        # 3æ‰¹
        third = page_count // 3
        return [third, third, page_count - 2 * third]
    elif page_count <= 150:
        # 3æ‰¹ï¼Œæ¯æ‰¹çº¦50é¡µ
        return [50, 50, page_count - 100]
    else:
        # 4æ‰¹ï¼Œæ¯æ‰¹çº¦50é¡µï¼Œæœ€å¤š200é¡µ
        page_count = min(page_count, 200)
        return [50, 50, 50, page_count - 150]


def generate_ppt_plan(
    topic: str,
    audience: str,
    page_count: int = 0,
    description: str = "",
    auto_page_count: bool = False,
    config: Optional[AIConfig] = None,
    progress_callback: callable = None
) -> Dict[str, Any]:
    """è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ PPT ç»“æ„ï¼ˆæ”¯æŒåˆ†æ‰¹ç”Ÿæˆå¤§å‹ PPTï¼‰
    
    Args:
        topic: PPT ä¸»é¢˜
        audience: ç›®æ ‡å—ä¼—
        page_count: å†…å®¹é¡µæ•°é‡ï¼ˆä¸å«å°é¢ï¼‰
        description: è¯¦ç»†æè¿°/è¦ç‚¹/å‚è€ƒèµ„æ–™
        auto_page_count: æ˜¯å¦è®© AI è‡ªåŠ¨åˆ¤æ–­é¡µæ•°
        config: AI é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current_batch, total_batches, message)
        
    Returns:
        åŒ…å« PPT ç»“æ„çš„å­—å…¸
        
    Raises:
        AIClientError: å½“ API è°ƒç”¨å¤±è´¥æ—¶
        JSONParseError: å½“è¿”å›æ ¼å¼é”™è¯¯æ—¶
    """
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
    if config is None:
        config = settings.to_ai_config()
    
    config.validate()
    
    # è®¡ç®—æ˜¯å¦éœ€è¦åˆ†æ‰¹
    batches = _calculate_batches(page_count) if not auto_page_count and page_count > 35 else [page_count]
    total_batches = len(batches)
    
    if total_batches > 1:
        print(f"\nğŸ“¦ é¡µæ•°è¾ƒå¤šï¼ˆ{page_count}é¡µï¼‰ï¼Œå°†åˆ† {total_batches} æ‰¹ç”Ÿæˆ...")
        return _generate_ppt_plan_batched(
            topic, audience, batches, description, config, progress_callback
        )
    
    # å•æ‰¹ç”Ÿæˆ
    return _generate_ppt_plan_single(
        topic, audience, page_count, description, auto_page_count, config
    )


def _generate_ppt_plan_batched(
    topic: str,
    audience: str,
    batches: list,
    description: str,
    config: AIConfig,
    progress_callback: callable = None
) -> Dict[str, Any]:
    """åˆ†æ‰¹ç”Ÿæˆ PPT ç»“æ„"""
    from core.prompt_builder import get_system_prompt
    
    client = OpenAI(
        api_key=config.api_key,
        base_url=config.api_base_url,
        timeout=config.timeout
    )
    
    total_batches = len(batches)
    all_slides = []
    title = ""
    subtitle = ""
    
    # è®°å½•å·²ç”Ÿæˆçš„å†…å®¹æ‘˜è¦ï¼Œç”¨äºç»­å†™
    generated_summary = []
    
    for batch_idx, batch_pages in enumerate(batches):
        current_batch = batch_idx + 1
        
        if progress_callback:
            progress_callback(current_batch, total_batches, f"æ­£åœ¨ç”Ÿæˆç¬¬ {current_batch}/{total_batches} æ‰¹...")
        
        print(f"\nğŸ”„ ç”Ÿæˆç¬¬ {current_batch}/{total_batches} æ‰¹ï¼ˆ{batch_pages} é¡µï¼‰...")
        
        # æ„å»ºåˆ†æ‰¹æç¤ºè¯
        if batch_idx == 0:
            # ç¬¬ä¸€æ‰¹ï¼šç”Ÿæˆå¼€å¤´éƒ¨åˆ†
            batch_prompt = _build_batch_prompt_first(
                topic, audience, batch_pages, total_batches, description
            )
        else:
            # åç»­æ‰¹æ¬¡ï¼šç»­å†™
            batch_prompt = _build_batch_prompt_continue(
                topic, audience, batch_pages, current_batch, total_batches,
                generated_summary, is_last=(current_batch == total_batches)
            )
        
        system_prompt = get_system_prompt()
        
        try:
            content = _call_api_with_retry(
                client=client,
                model_name=config.model_name,
                system_prompt=system_prompt,
                user_prompt=batch_prompt,
                max_retries=config.max_retries,
                temperature=config.temperature
            )
            
            cleaned_content = _clean_json_response(content)
            batch_result = json.loads(cleaned_content)
            
            # æå–æ ‡é¢˜ï¼ˆåªä»ç¬¬ä¸€æ‰¹è·å–ï¼‰
            if batch_idx == 0:
                title = batch_result.get("title", topic)
                subtitle = batch_result.get("subtitle", "")
            
            # æ”¶é›† slides
            batch_slides = batch_result.get("slides", [])
            
            # è¿‡æ»¤æ‰ ending é¡µï¼ˆé™¤äº†æœ€åä¸€æ‰¹ï¼‰
            if current_batch < total_batches:
                batch_slides = [s for s in batch_slides if s.get("type") != "ending"]
            
            all_slides.extend(batch_slides)
            
            # è®°å½•æ‘˜è¦ç”¨äºç»­å†™
            for slide in batch_slides:
                slide_title = slide.get("title", "")
                if slide_title:
                    generated_summary.append(slide_title)
            
            print(f"âœ“ ç¬¬ {current_batch} æ‰¹å®Œæˆï¼Œè·å¾— {len(batch_slides)} é¡µ")
            
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {current_batch} æ‰¹ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    # åˆå¹¶ç»“æœ
    result = {
        "title": title,
        "subtitle": subtitle,
        "slides": all_slides
    }
    
    print(f"\nâœ… åˆ†æ‰¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(all_slides)} é¡µ")
    return result


def _build_batch_prompt_first(topic: str, audience: str, pages: int, total_batches: int, description: str) -> str:
    """æ„å»ºç¬¬ä¸€æ‰¹çš„æç¤ºè¯"""
    prompt = f"""è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜åˆ›ä½œ PPT çš„ã€å¼€å¤´éƒ¨åˆ†ã€‘ï¼š

ä¸»é¢˜ï¼š{topic}
ç›®æ ‡å—ä¼—ï¼š{audience}
æœ¬æ‰¹é¡µæ•°ï¼š{pages} é¡µï¼ˆè¿™æ˜¯ç¬¬ 1/{total_batches} æ‰¹ï¼Œåç»­è¿˜ä¼šç»§ç»­ç”Ÿæˆï¼‰

âš ï¸ é‡è¦è¯´æ˜ï¼š
- è¿™æ˜¯åˆ†æ‰¹ç”Ÿæˆçš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œè¯·ç”Ÿæˆ PPT çš„å¼€å¤´å†…å®¹
- åŒ…å«ï¼šå°é¢ä¿¡æ¯ï¼ˆtitle, subtitleï¼‰+ å‰ {pages} é¡µå†…å®¹
- ä¸è¦ç”Ÿæˆ ending ç»“æŸé¡µï¼ˆåç»­æ‰¹æ¬¡ä¼šç”Ÿæˆï¼‰
- å†…å®¹è¦å®Œæ•´ï¼Œä¸ºåç»­æ‰¹æ¬¡ç•™å¥½è¡”æ¥"""

    if description:
        prompt += f"\n\nã€å‚è€ƒèµ„æ–™ã€‘\n{description}"
    
    prompt += """

è¯·ç”Ÿæˆ JSON æ ¼å¼ï¼ŒåŒ…å« titleã€subtitle å’Œ slides æ•°ç»„ã€‚"""
    return prompt


def _build_batch_prompt_continue(topic: str, audience: str, pages: int, 
                                  current_batch: int, total_batches: int,
                                  generated_summary: list, is_last: bool) -> str:
    """æ„å»ºç»­å†™æ‰¹æ¬¡çš„æç¤ºè¯"""
    summary_text = "\n".join([f"- {t}" for t in generated_summary[-10:]])  # æœ€è¿‘10é¡µæ‘˜è¦
    
    prompt = f"""è¯·ç»§ç»­ç”Ÿæˆ PPT çš„ã€ç¬¬ {current_batch} éƒ¨åˆ†ã€‘ï¼š

ä¸»é¢˜ï¼š{topic}
ç›®æ ‡å—ä¼—ï¼š{audience}
æœ¬æ‰¹é¡µæ•°ï¼š{pages} é¡µï¼ˆè¿™æ˜¯ç¬¬ {current_batch}/{total_batches} æ‰¹ï¼‰

ã€å·²ç”Ÿæˆçš„å†…å®¹æ‘˜è¦ã€‘ï¼ˆè¯·ç»­å†™ï¼Œä¸è¦é‡å¤ï¼‰ï¼š
{summary_text}

âš ï¸ é‡è¦è¯´æ˜ï¼š
- è¿™æ˜¯ç»­å†™éƒ¨åˆ†ï¼Œè¯·æ¥ç€ä¸Šé¢çš„å†…å®¹ç»§ç»­
- ä¸è¦é‡å¤å·²ç”Ÿæˆçš„å†…å®¹
- æœ¬æ‰¹ç”Ÿæˆ {pages} é¡µæ–°å†…å®¹"""

    if is_last:
        prompt += "\n- è¿™æ˜¯æœ€åä¸€æ‰¹ï¼Œè¯·åœ¨æœ€åæ·»åŠ  ending ç»“æŸé¡µ"
    else:
        prompt += "\n- ä¸è¦ç”Ÿæˆ ending ç»“æŸé¡µï¼ˆåç»­æ‰¹æ¬¡ä¼šç”Ÿæˆï¼‰"
    
    prompt += """

è¯·ç”Ÿæˆ JSON æ ¼å¼ï¼Œåªéœ€è¦ slides æ•°ç»„ï¼ˆä¸éœ€è¦ title å’Œ subtitleï¼‰ã€‚"""
    return prompt


def _generate_ppt_plan_single(
    topic: str,
    audience: str,
    page_count: int,
    description: str,
    auto_page_count: bool,
    config: AIConfig
) -> Dict[str, Any]:
    """å•æ‰¹ç”Ÿæˆ PPT ç»“æ„ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
    client = OpenAI(
        api_key=config.api_key,
        base_url=config.api_base_url,
        timeout=config.timeout
    )
    
    system_prompt = get_system_prompt()
    user_prompt = build_user_prompt(topic, audience, page_count, description, auto_page_count)
    
    print(f"\n{'=' * 60}")
    print(f"ğŸ“ ç”Ÿæˆ PPT: {topic}")
    print(f"ğŸ¯ ç›®æ ‡å—ä¼—: {audience}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {config.model_name}")
    print(f"{'=' * 60}\n")
    
    try:
        content = _call_api_with_retry(
            client=client,
            model_name=config.model_name,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            max_retries=config.max_retries,
            temperature=config.temperature
        )
        
        print(f"ğŸ“„ AI è¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        content_lower = content.strip().lower()
        if content_lower.startswith('<!doctype') or content_lower.startswith('<html') or '<html' in content_lower[:500]:
            raise AIClientError(
                f"API è¿”å›äº† HTML é¡µé¢è€Œä¸æ˜¯ AI å“åº”ã€‚è¯·æ£€æŸ¥ï¼š\n"
                f"1. API Base URL æ˜¯å¦æ­£ç¡®ï¼ˆå½“å‰: {config.api_base_url}ï¼‰\n"
                f"2. ç¡®ä¿ URL ä»¥ /v1 ç»“å°¾\n"
                f"3. API Key æ˜¯å¦æœ‰æ•ˆ"
            )
        
        cleaned_content = _clean_json_response(content)
        
        if not cleaned_content:
            raise JSONParseError(f"AI è¿”å›äº†æ— æ•ˆå†…å®¹: {content[:300]}")
        
        plan_dict = json.loads(cleaned_content)
        
        return plan_dict
        
    except json.JSONDecodeError as e:
        error_msg = _build_json_error_message(e, locals().get('content', ''))
        raise JSONParseError(error_msg)
    except AIClientError:
        raise
    except Exception as e:
        raise AIClientError(f"ç”Ÿæˆå¤±è´¥: {e}")


def _build_json_error_message(error: json.JSONDecodeError, content: str) -> str:
    """æ„å»º JSON è§£æé”™è¯¯æ¶ˆæ¯"""
    msg = "AI è¿”å›çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"
    msg += f"  é”™è¯¯è¯¦æƒ…: {error}"
    
    if content:
        preview = content[:200].replace('\n', ' ')
        msg += f"  è¿”å›å†…å®¹é¢„è§ˆ: {preview}"
    
    return msg


def test_api_connection(config: AIConfig) -> Dict[str, Any]:
    """æµ‹è¯• API è¿é€šæ€§
    
    Args:
        config: AI é…ç½®
        
    Returns:
        æµ‹è¯•ç»“æœå­—å…¸ï¼ŒåŒ…å« success, message, model_info ç­‰
    """
    result = {
        "success": False,
        "message": "",
        "model": config.model_name,
        "api_base": config.api_base_url,
        "response_time": 0,
    }
    
    try:
        config.validate()
    except ValueError as e:
        result["message"] = str(e)
        return result
    
    import time
    start_time = time.time()
    
    try:
        client = OpenAI(
            api_key=config.api_key,
            base_url=config.api_base_url,
            timeout=15  # æµ‹è¯•ç”¨è¾ƒçŸ­è¶…æ—¶
        )
        
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        response = client.chat.completions.create(
            model=config.model_name,
            messages=[{"role": "user", "content": "Hi, just testing. Reply with: OK"}],
            max_tokens=10,
            temperature=0
        )
        
        elapsed = time.time() - start_time
        result["response_time"] = round(elapsed * 1000)  # æ¯«ç§’
        
        # æ£€æŸ¥å“åº”
        content = None
        if hasattr(response, 'choices') and response.choices:
            message = response.choices[0].message
            content = message.content if message else None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çŠ¶æ€ï¼ˆæŸäº› API è¿”å›ç‰¹æ®Šæ ¼å¼ï¼‰
        if hasattr(response, 'status') and response.status:
            status = str(response.status)
            if status != '200' and status != 'success':
                msg = getattr(response, 'msg', '') or f"çŠ¶æ€ç : {status}"
                result["message"] = f"API è¿”å›é”™è¯¯: {msg}"
                return result
        
        if not content:
            result["message"] = "API è¿”å›äº†ç©ºå“åº”ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®"
            return result
        
        # æ£€æŸ¥æ˜¯å¦è¿”å› HTML
        content_lower = content.strip().lower()
        if content_lower.startswith('<!doctype') or content_lower.startswith('<html') or '<html' in content_lower[:500]:
            result["message"] = f"API è¿”å›äº† HTML é¡µé¢ã€‚è¯·æ£€æŸ¥ API Base URL æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ä»¥ /v1 ç»“å°¾ï¼ˆå½“å‰: {config.api_base_url}ï¼‰"
            return result
        
        result["success"] = True
        result["message"] = f"è¿æ¥æˆåŠŸï¼å“åº”æ—¶é—´: {result['response_time']}ms"
        result["response"] = content[:100]
        
    except RateLimitError:
        result["message"] = "API é™æµï¼Œä½†è¿æ¥æ­£å¸¸ã€‚è¯·ç¨åå†è¯•"
        result["success"] = True  # é™æµè¯´æ˜ API æ˜¯é€šçš„
    except APIConnectionError as e:
        result["message"] = f"ç½‘ç»œè¿æ¥å¤±è´¥: {e}"
    except APIError as e:
        error_str = str(e).lower()
        if "401" in error_str or "invalid_api_key" in error_str:
            result["message"] = "API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥"
        elif "404" in error_str:
            result["message"] = "æ¨¡å‹ä¸å­˜åœ¨æˆ– API è·¯å¾„é”™è¯¯"
        else:
            result["message"] = f"API é”™è¯¯: {e}"
    except Exception as e:
        result["message"] = f"æµ‹è¯•å¤±è´¥: {e}"
    
    return result
